# -*- coding: utf-8 -*-
"""Get AnimeDetails from AnicrushAPI.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fY53pQEeyXkta8vrhYl1bd04hJjyXKIm
"""

#!pip install boto3
#!pip install s3fs

import requests
import pandas as pd
from pandas import json_normalize
import boto3

URL="https://api.anicrush.to/"
COMMENT_ENDPOINT="v1/comment/list"
ANIME_INFO="shared/v2/movie/list"
s3=boto3.resource(
    service_name='s3',
    region_name='ap-south-1',
    aws_access_key_id='AKIAW3MEFXW7FMKXZGXR',
    aws_secret_access_key='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'
)

def getUrlbuilderFromPageIndexAndLimit(limit,endpoint,page):
  return URL+endpoint+"?firstLetter=&limit="+str(limit)+"&page="+str(page)

def getPagesFromWebsite(pageCount):
  for i in range(0,pageCount):
    break
    #Logic if page by page is taken

def getDataFrameFromAnimeAPIResponse(animeList):
  animeListDf=json_normalize(animeList)
  animeListDf['genres'].apply(lambda x: [i['name'] for i in x])
  animeListDf['genres']=animeListDf['genres'].map(lambda x: ','.join([i['name'] for i in x]))
  return animeListDf

def getNumberOfAnimePagesFromAPIRespone(response):
  #here
  try:
    print("Number of Anime pages: "+str(response['result']['totalPages']))
    return response['result']['totalPages']
  except:
    print('Error in getting number of AnimeList')
    return 0

defaultUrl = "https://api.anicrush.to/shared/v2/movie/list?firstLetter=&limit=24&page=1"
headers = {
        'Accept': 'application/json, text/plain, */*',
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36',
        'Referer': 'https://anicrush.to/',
        'Access-Control-Allow-Origin':'*',
        'Sec-Ch-Ua' : "\"Google Chrome\";v=\"123\", \"Not:A-Brand\";v=\"8\", \"Chromium\";v=\"123\"",
        'Sec-Ch-Ua-Mobile':'?0',
        'Sec-Ch-Ua-Platform':"Windows",
        'X-Site':'anicrush'
    }

defaultResponse = requests.get(defaultUrl, headers=headers)
st=getUrlbuilderFromPageIndexAndLimit(int(defaultResponse.json()['result']['totalItems']),ANIME_INFO,1)
animeResponse=requests.get(st, headers=headers)
finalDf=getDataFrameFromAnimeAPIResponse(animeResponse.json()['result']['movies'])
finalDf.to_csv('AnimeListFromAnicrush.csv', index=False, encoding='utf-8')

"""Upload in s3 bucket

"""

s3.Bucket('anicrushdatas').upload_file(Filename='AnimeListFromAnicrush.csv',Key='AnimeListFromAnicrush.csv')